{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNeATLKznL3u",
        "outputId": "10f0acf3-a90c-480d-f5b9-171136c9cd00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m71.7/76.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.6/274.6 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.9/86.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gradio==3.18.0\n",
            "  Downloading gradio-3.18.0-py3-none-any.whl (14.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.2/14.2 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles (from gradio==3.18.0)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from gradio==3.18.0) (3.9.3)\n",
            "Requirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.18.0) (4.2.2)\n",
            "Collecting fastapi (from gradio==3.18.0)\n",
            "  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio==3.18.0)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio==3.18.0) (2023.6.0)\n",
            "Collecting httpx (from gradio==3.18.0)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from gradio==3.18.0) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py[linkify,plugins]>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.18.0) (3.0.0)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from gradio==3.18.0) (2.1.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gradio==3.18.0) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gradio==3.18.0) (1.25.2)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.10/dist-packages (from gradio==3.18.0) (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from gradio==3.18.0) (1.5.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from gradio==3.18.0) (9.4.0)\n",
            "Collecting pycryptodome (from gradio==3.18.0)\n",
            "  Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from gradio==3.18.0) (2.6.4)\n",
            "Collecting pydub (from gradio==3.18.0)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio==3.18.0)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from gradio==3.18.0) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gradio==3.18.0) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from gradio==3.18.0) (4.10.0)\n",
            "Collecting uvicorn (from gradio==3.18.0)\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.0 (from gradio==3.18.0)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio==3.18.0) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio==3.18.0) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio==3.18.0) (0.12.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify,plugins]>=2.0.0->gradio==3.18.0) (0.1.2)\n",
            "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify,plugins]>=2.0.0->gradio==3.18.0) (2.0.3)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify,plugins]>=2.0.0->gradio==3.18.0) (0.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio==3.18.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio==3.18.0) (2023.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.18.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.18.0) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.18.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.18.0) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.18.0) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.18.0) (4.0.3)\n",
            "Collecting starlette<0.37.0,>=0.36.3 (from fastapi->gradio==3.18.0)\n",
            "  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->gradio==3.18.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic->gradio==3.18.0) (2.16.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.18.0) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.18.0) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx->gradio==3.18.0)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.18.0) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.18.0) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->gradio==3.18.0)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.18.0) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.18.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.18.0) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.18.0) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.18.0) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.18.0) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->gradio==3.18.0) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gradio==3.18.0) (2.0.7)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn->gradio==3.18.0) (8.1.7)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.18.0) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.18.0) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.18.0) (0.18.0)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify,plugins]>=2.0.0->gradio==3.18.0) (1.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->gradio==3.18.0) (1.16.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->gradio==3.18.0) (1.2.0)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=e54e9f319b8dfce43f9ffdbd460f04de0331552b49753986e31fb52cda237597\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, python-multipart, pycryptodome, h11, aiofiles, uvicorn, starlette, httpcore, httpx, fastapi, gradio\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.110.0 ffmpy-0.3.2 gradio-3.18.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 pycryptodome-3.20.0 pydub-0.25.1 python-multipart-0.0.9 starlette-0.36.3 uvicorn-0.29.0 websockets-12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==0.28\n",
        "!pip install PyPDF2\n",
        "!pip install -q langchain\n",
        "!pip install gradio==3.18.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import PyPDF2\n",
        "\n",
        "def extract_text_from_binary(file_path):\n",
        "    text = \"\"\n",
        "    # Open the file in binary read mode\n",
        "    with open(file_path, 'rb') as file:\n",
        "        pdf_data = file.read()\n",
        "\n",
        "    # Now that you have the binary content, use it with PyPDF2\n",
        "    pdf_data = io.BytesIO(pdf_data)\n",
        "    reader = PyPDF2.PdfReader(pdf_data)\n",
        "    num_pages = len(reader.pages)\n",
        "\n",
        "    for page in range(num_pages):\n",
        "        current_page = reader.pages[page]\n",
        "        page_text = current_page.extract_text()\n",
        "        if page_text:  # Check if page_text is not None or empty\n",
        "            text += page_text\n",
        "    return text\n",
        "\n",
        "# Path to your PDF file\n",
        "resume_path = \"/content/Barghavani_MLengineer.pdf\"\n",
        "\n",
        "# Extract text from the PDF\n",
        "resume_text = extract_text_from_binary(resume_path)\n"
      ],
      "metadata": {
        "id": "dkzUf4JinWpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resume_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "FUySNZivnY_5",
        "outputId": "0564e5b4-76bd-49a2-e485-d54062959428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Bahareh Arghavani Nobar Machine learning engineer  Email: bargh1@unh.newhaven.edu                                                                                                           Phone: 8609445353 LinkedIn: www.linkedin.com/in/bahareh-arghavan/                                                                             Address: Shelton ,CT Github: https://github.com/barghavanii?tab=repositories                 Higgin Face: https://huggingface.co/barghavani  SUMMARY  Engineered and deployed a revolutionary LLM-based Text-to-Speech (TTS) plugin, driving a remarkable 15% boost in user engagement and achieving an industry-leading Mean Opinion Score of 4.2. Pioneered the development of an open-source database for Persian TTS, significantly advancing language processing technology. Optimizations of GPT and wav2vec models resulted in a 40% reduction in evaluation times and a 25% improvement in model accuracy. Directed predictive analytics initiatives at Maadiran Industries Group, enhancing fulfillment speeds by 20%.  SKILLS  • Languages: Python, MySQL. • Libraries/Frameworks: Numpy, Pandas, PyTorch, TensorFlow, Keras, Scikit-learn, Matplotlib, Seaborn. • Machine Learning: Supervised and Unsupervised Learning, Neural Networks, NLP (BERT, GPT), Reinforcement Learning, Generative Models like GANs and VAE, Big Data Technologies, Data Visualization with Tensorboard • Cloud: AWS EC2, EMR, S3 • Databases: SQLite, MySQL, MongoDB • Machine Learning Algorithms: K-means clustering, Bagging (Bootstrap Aggregating), Boosting, Logistic regression, Linear regression. • NLP: Tokenization, Word Embeddings, Text Classification, BERT, GPT, LLMs, Text-to-Speech with Xtts, VITS, Multimodal Technologies, Speech Recognition, Zero shot learning, Finetuning.  WORK  EXPERIENCE         Machine Learning Engineer (Graduate Research Assistant) University of New Haven ,Secure and Assured Intelligent Learning(SAIL) LAB              October 2022 - Present  Transformer based Text-To-Speech for Low Resource Languages ● Led the creation of an innovative web browser plugin utilizing LLM technology to deliver high-quality Text-to-Speech functionality for diverse Persian accents; the plugin garnered an exceptional Mean Opinion Score (MOS) of 4.2, outperforming industry benchmarks by 20%. ● Architected an innovative open-source database specifically crafted for Persian Text-to-speech technology, paving the way for enhanced development capabilities and fostering cutting-edge advancements in language processing.(Project page). ● Optimized GPT training and fine-tuned wav2vec model for automated MOS evaluation, resulting in 40% faster evaluation times and improved accuracy by 25%. ● Led the fine-tuning of xTTS technology, enhancing text-to-speech capabilities and delivering a 15% increase in user engagement through improved audio quality.  Fault detection in medical devices ● Assessed three generative models (VAE, GAN, and HMM) for fault detection methods using rigorous design principles. ● Analyzed and applied generative machine learning models to surgical staplers and Airbus datasets, achieving a 25% improvement in predicting equipment failure rates and reducing operational downtime by 20%.  ● Analyzed the impact of varying window sizes on model performance through rigorous downsampling techniques, resulting in a 15% increase in model accuracy and a 20% reduction in false positive predictions.  ● Assessed generative models for fault detection: Variational Autoencoder (97%), Generative Adversarial Network (95%), Hidden Markov Model (82%); instrumental in determining the most effective model for enhancing fault detection capabilities.  ● Conducted comprehensive model evaluation, demonstrating the efficacy of larger datasets in enhancing accuracy metrics by 20%; findings presented in research publication: 'Comparative Study of Generative Models for Early Detection of Failures in Medical Devices’.  Data analyst Maadiran industries group, TCL exclusive representative                                      December 2017 – August 2022  ● Implemented data-driven cost-saving strategies, including renegotiating vendor contracts and streamlining inventory management, leading to a 10% reduction in operational expenses and a 20% increase in fulfillment speed. ● Engineered an optimized supply chain strategy for global suppliers, securing advantageous contracts and implementing vendor performance metrics; Achieved a 25% improvement in on-time delivery and slashed shipping costs by $80,000 quarterly. ● Directed data-driven insights and financial analyses to inform strategic decision-making; implemented predictive analytics model that reduced operational costs by 10% and enhanced profitability by 15%.  ● Cultivated and mentored team members, leading to a 25% improvement in team performance.  EDUCATION  University of New Haven, Master of data science, West Haven, CT                                          August 2022 - May 2024  Kharazmi University, Bachelor of computer science, Tehran                                         September 2012 - September 2016  ACTIVITIES  Awarded the prestigious 2023-2024 TCoE Endowed Graduate Fellowship for exceptional academic achievements and dedicated commitment to pioneering research in AI technologies for social impact.                     August 2023 - May 2024 Executive board member, Data science club ,University of New Haven, played a key role in fostering a community of collaboration and learning among club members, enhancing the club's impact on campus   March 2023 - Present                                                  \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Replace 'YOUR_OPENAI_API_KEY' with your actual key\n",
        "os.environ['OPENAI_API_KEY'] = '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'\n",
        "from langchain.llms import OpenAIChat\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain import LLMChain, PromptTemplate\n",
        "\n",
        "template = \"\"\"Format the provided resume to this YAML template:\n",
        "---\n",
        "name: ''\n",
        "phoneNumbers:\n",
        "- ''\n",
        "websites:\n",
        "- ''\n",
        "emails:\n",
        "- ''\n",
        "dateOfBirth: ''\n",
        "addresses:\n",
        "- street: ''\n",
        "  city: ''\n",
        "  state: ''\n",
        "  zip: ''\n",
        "  country: ''\n",
        "summary: ''\n",
        "education:\n",
        "- school: ''\n",
        "  degree: ''\n",
        "  fieldOfStudy: ''\n",
        "  startDate: ''\n",
        "  endDate: ''\n",
        "workExperience:\n",
        "- company: ''\n",
        "  position: ''\n",
        "  startDate: ''\n",
        "  endDate: ''\n",
        "skills:\n",
        "- name: ''\n",
        "certifications:\n",
        "- name: ''\n",
        "\n",
        "{chat_history}\n",
        "{human_input}\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"chat_history\", \"human_input\"],\n",
        "    template=template\n",
        ")\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "\n",
        "llm_chain = LLMChain(\n",
        "    llm=OpenAIChat(model=\"gpt-3.5-turbo\"),\n",
        "    prompt=prompt,\n",
        "    verbose=True,\n",
        "    memory=memory,\n",
        ")\n",
        "\n",
        "# Define your function here\n",
        "def format_resume_to_yaml(resume):\n",
        "    res = llm_chain.predict(human_input=resume)\n",
        "    return res\n",
        "\n",
        "# Assuming 'resume' is a variable holding the resume text you wish to format\n",
        "formatted_resume_yaml = format_resume_to_yaml(resume_text)\n",
        "\n",
        "# Print the formatted resume in YAML\n",
        "print(formatted_resume_yaml)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyINzrc7neeP",
        "outputId": "65965095-4156-42bd-8639-b584476c03b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAIChat` was deprecated in langchain-community 0.0.1 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_community/llms/openai.py:1070: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mFormat the provided resume to this YAML template:\n",
            "---\n",
            "name: ''\n",
            "phoneNumbers:\n",
            "- ''\n",
            "websites:\n",
            "- ''\n",
            "emails:\n",
            "- ''\n",
            "dateOfBirth: ''\n",
            "addresses:\n",
            "- street: ''\n",
            "  city: ''\n",
            "  state: ''\n",
            "  zip: ''\n",
            "  country: ''\n",
            "summary: ''\n",
            "education:\n",
            "- school: ''\n",
            "  degree: ''\n",
            "  fieldOfStudy: ''\n",
            "  startDate: ''\n",
            "  endDate: ''\n",
            "workExperience:\n",
            "- company: ''\n",
            "  position: ''\n",
            "  startDate: ''\n",
            "  endDate: ''\n",
            "skills:\n",
            "- name: ''\n",
            "certifications:\n",
            "- name: ''\n",
            "\n",
            "\n",
            "Bahareh Arghavani Nobar Machine learning engineer  Email: bargh1@unh.newhaven.edu                                                                                                           Phone: 8609445353 LinkedIn: www.linkedin.com/in/bahareh-arghavan/                                                                             Address: Shelton ,CT Github: https://github.com/barghavanii?tab=repositories                 Higgin Face: https://huggingface.co/barghavani  SUMMARY  Engineered and deployed a revolutionary LLM-based Text-to-Speech (TTS) plugin, driving a remarkable 15% boost in user engagement and achieving an industry-leading Mean Opinion Score of 4.2. Pioneered the development of an open-source database for Persian TTS, significantly advancing language processing technology. Optimizations of GPT and wav2vec models resulted in a 40% reduction in evaluation times and a 25% improvement in model accuracy. Directed predictive analytics initiatives at Maadiran Industries Group, enhancing fulfillment speeds by 20%.  SKILLS  • Languages: Python, MySQL. • Libraries/Frameworks: Numpy, Pandas, PyTorch, TensorFlow, Keras, Scikit-learn, Matplotlib, Seaborn. • Machine Learning: Supervised and Unsupervised Learning, Neural Networks, NLP (BERT, GPT), Reinforcement Learning, Generative Models like GANs and VAE, Big Data Technologies, Data Visualization with Tensorboard • Cloud: AWS EC2, EMR, S3 • Databases: SQLite, MySQL, MongoDB • Machine Learning Algorithms: K-means clustering, Bagging (Bootstrap Aggregating), Boosting, Logistic regression, Linear regression. • NLP: Tokenization, Word Embeddings, Text Classification, BERT, GPT, LLMs, Text-to-Speech with Xtts, VITS, Multimodal Technologies, Speech Recognition, Zero shot learning, Finetuning.  WORK  EXPERIENCE         Machine Learning Engineer (Graduate Research Assistant) University of New Haven ,Secure and Assured Intelligent Learning(SAIL) LAB              October 2022 - Present  Transformer based Text-To-Speech for Low Resource Languages ● Led the creation of an innovative web browser plugin utilizing LLM technology to deliver high-quality Text-to-Speech functionality for diverse Persian accents; the plugin garnered an exceptional Mean Opinion Score (MOS) of 4.2, outperforming industry benchmarks by 20%. ● Architected an innovative open-source database specifically crafted for Persian Text-to-speech technology, paving the way for enhanced development capabilities and fostering cutting-edge advancements in language processing.(Project page). ● Optimized GPT training and fine-tuned wav2vec model for automated MOS evaluation, resulting in 40% faster evaluation times and improved accuracy by 25%. ● Led the fine-tuning of xTTS technology, enhancing text-to-speech capabilities and delivering a 15% increase in user engagement through improved audio quality.  Fault detection in medical devices ● Assessed three generative models (VAE, GAN, and HMM) for fault detection methods using rigorous design principles. ● Analyzed and applied generative machine learning models to surgical staplers and Airbus datasets, achieving a 25% improvement in predicting equipment failure rates and reducing operational downtime by 20%.  ● Analyzed the impact of varying window sizes on model performance through rigorous downsampling techniques, resulting in a 15% increase in model accuracy and a 20% reduction in false positive predictions.  ● Assessed generative models for fault detection: Variational Autoencoder (97%), Generative Adversarial Network (95%), Hidden Markov Model (82%); instrumental in determining the most effective model for enhancing fault detection capabilities.  ● Conducted comprehensive model evaluation, demonstrating the efficacy of larger datasets in enhancing accuracy metrics by 20%; findings presented in research publication: 'Comparative Study of Generative Models for Early Detection of Failures in Medical Devices’.  Data analyst Maadiran industries group, TCL exclusive representative                                      December 2017 – August 2022  ● Implemented data-driven cost-saving strategies, including renegotiating vendor contracts and streamlining inventory management, leading to a 10% reduction in operational expenses and a 20% increase in fulfillment speed. ● Engineered an optimized supply chain strategy for global suppliers, securing advantageous contracts and implementing vendor performance metrics; Achieved a 25% improvement in on-time delivery and slashed shipping costs by $80,000 quarterly. ● Directed data-driven insights and financial analyses to inform strategic decision-making; implemented predictive analytics model that reduced operational costs by 10% and enhanced profitability by 15%.  ● Cultivated and mentored team members, leading to a 25% improvement in team performance.  EDUCATION  University of New Haven, Master of data science, West Haven, CT                                          August 2022 - May 2024  Kharazmi University, Bachelor of computer science, Tehran                                         September 2012 - September 2016  ACTIVITIES  Awarded the prestigious 2023-2024 TCoE Endowed Graduate Fellowship for exceptional academic achievements and dedicated commitment to pioneering research in AI technologies for social impact.                     August 2023 - May 2024 Executive board member, Data science club ,University of New Haven, played a key role in fostering a community of collaboration and learning among club members, enhancing the club's impact on campus   March 2023 - Present                                                  \u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "```yaml\n",
            "name: Bahareh Arghavani Nobar\n",
            "phoneNumbers:\n",
            "  - 8609445353\n",
            "websites:\n",
            "  - www.linkedin.com/in/bahareh-arghavan/\n",
            "  - https://github.com/barghavanii?tab=repositories\n",
            "  - https://huggingface.co/barghavani\n",
            "emails:\n",
            "  - bargh1@unh.newhaven.edu                                                                                                                                                                           \n",
            "dateOfBirth: ''\n",
            "addresses:\n",
            "  - street: ''\n",
            "    city: Shelton\n",
            "    state: CT\n",
            "    zip: ''\n",
            "    country: ''\n",
            "summary: |\n",
            "  Engineered and deployed a revolutionary LLM-based Text-to-Speech (TTS) plugin, driving a remarkable 15% boost in user engagement and achieving an industry-leading Mean Opinion Score of 4.2. Pioneered the development of an open-source database for Persian TTS, significantly advancing language processing technology. Optimizations of GPT and wav2vec models resulted in a 40% reduction in evaluation times and a 25% improvement in model accuracy. Directed predictive analytics initiatives at Maadiran Industries Group, enhancing fulfillment speeds by 20.\n",
            "education:\n",
            "  - school: University of New Haven\n",
            "    degree: Master of data science\n",
            "    fieldOfStudy: ''\n",
            "    startDate: August 2022\n",
            "    endDate: May 2024\n",
            "  - school: Kharazmi University\n",
            "    degree: Bachelor of computer science\n",
            "    fieldOfStudy: ''\n",
            "    startDate: September 2012\n",
            "    endDate: September 2016\n",
            "workExperience:\n",
            "  - company: University of New Haven\n",
            "    position: Machine Learning Engineer (Graduate Research Assistant)\n",
            "    startDate: October 2022\n",
            "    endDate: Present\n",
            "  - company: Maadiran Industries Group, TCL exclusive representative\n",
            "    position: Data Analyst\n",
            "    startDate: December 2017\n",
            "    endDate: August 2022\n",
            "skills:\n",
            "  - name: Python\n",
            "  - name: MySQL\n",
            "  - name: Numpy\n",
            "  - name: Pandas\n",
            "  - name: PyTorch\n",
            "  - name: TensorFlow\n",
            "  - name: Keras\n",
            "  - name: Scikit-learn\n",
            "  - name: Matplotlib\n",
            "  - name: Seaborn\n",
            "  - name: Supervised and Unsupervised Learning\n",
            "  - name: Neural Networks\n",
            "  - name: NLP (BERT, GPT)\n",
            "  - name: Reinforcement Learning\n",
            "  - name: Generative Models like GANs and VAE\n",
            "  - name: Big Data Technologies\n",
            "  - name: Data Visualization with Tensorboard\n",
            "  - name: AWS EC2\n",
            "  - name: EMR\n",
            "  - name: S3\n",
            "  - name: SQLite\n",
            "  - name: MySQL\n",
            "  - name: MongoDB\n",
            "  - name: K-means clustering\n",
            "  - name: Bagging (Bootstrap Aggregating)\n",
            "  - name: Boosting\n",
            "  - name: Logistic regression\n",
            "  - name: Linear regression\n",
            "  - name: Tokenization\n",
            "  - name: Word Embeddings\n",
            "  - name: Text Classification\n",
            "  - name: BERT\n",
            "  - name: GPT\n",
            "  - name: LLMs\n",
            "  - name: Text-to-Speech with Xtts, VITS\n",
            "  - name: Multimodal Technologies\n",
            "  - name: Speech Recognition\n",
            "  - name: Zero shot learning\n",
            "  - name: Finetuning\n",
            "  - name: Hugging Face\n",
            "certifications:\n",
            "  - name: ''\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Huggingface space deployment Upload a pdf and the parsed result will be provided as YAML"
      ],
      "metadata": {
        "id": "0Ek-VvHHQiX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import os\n",
        "import io\n",
        "import PyPDF2\n",
        "#from langchain.llms import OpenAIChat\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "\n",
        "# Updated imports for Gradio components\n",
        "from gradio.components import File, Textbox\n",
        "\n",
        "def extract_text_from_pdf_binary(pdf_binary):\n",
        "    text = \"\"\n",
        "    pdf_data = io.BytesIO(pdf_binary)\n",
        "    reader = PyPDF2.PdfReader(pdf_data)\n",
        "    num_pages = len(reader.pages)\n",
        "\n",
        "    for page in range(num_pages):\n",
        "        current_page = reader.pages[page]\n",
        "        page_text = current_page.extract_text()\n",
        "        if page_text:  # Check if page_text is not None or empty\n",
        "            text += page_text\n",
        "    return text\n",
        "\n",
        "def format_resume_to_yaml(api_key, file_content):\n",
        "    # Set the API key for OpenAI\n",
        "    os.environ['OPENAI_API_KEY'] = api_key\n",
        "\n",
        "    # Check if the file content is not empty\n",
        "    if not file_content:\n",
        "        raise ValueError(\"The uploaded file is empty.\")\n",
        "\n",
        "    # Extract text from the uploaded PDF binary\n",
        "    resume_text = extract_text_from_pdf_binary(file_content)\n",
        "\n",
        "    template = \"\"\"Format the provided resume to this YAML template:\n",
        "    ---\n",
        "    name: ''\n",
        "    phoneNumbers:\n",
        "    - ''\n",
        "    websites:\n",
        "    - ''\n",
        "    emails:\n",
        "    - ''\n",
        "    dateOfBirth: ''\n",
        "    addresses:\n",
        "    - street: ''\n",
        "      city: ''\n",
        "      state: ''\n",
        "      zip: ''\n",
        "      country: ''\n",
        "    summary: ''\n",
        "    education:\n",
        "    - school: ''\n",
        "      degree: ''\n",
        "      fieldOfStudy: ''\n",
        "      startDate: ''\n",
        "      endDate: ''\n",
        "    workExperience:\n",
        "    - company: ''\n",
        "      position: ''\n",
        "      startDate: ''\n",
        "      endDate: ''\n",
        "    skills:\n",
        "    - name: ''\n",
        "    certifications:\n",
        "    - name: ''\n",
        "    {chat_history}\n",
        "    {human_input}\"\"\"\n",
        "\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"chat_history\", \"human_input\"],\n",
        "        template=template\n",
        "    )\n",
        "\n",
        "    memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "\n",
        "    llm_chain = LLMChain(\n",
        "        llm=ChatOpenAI(model=\"gpt-3.5-turbo\"),\n",
        "        prompt=prompt,\n",
        "        verbose=True,\n",
        "        memory=memory,\n",
        "    )\n",
        "\n",
        "    res = llm_chain.predict(human_input=resume_text)\n",
        "    return res\n",
        "\n",
        "def main():\n",
        "    input_api_key = Textbox(label=\"Enter your OpenAI API Key\")\n",
        "    input_pdf_file = File(label=\"Upload your PDF resume\", type=\"binary\")\n",
        "    output_yaml = Textbox(label=\"Formatted Resume in YAML\")\n",
        "\n",
        "    iface = gr.Interface(\n",
        "        fn=format_resume_to_yaml,\n",
        "        inputs=[input_api_key, input_pdf_file],\n",
        "        outputs=output_yaml,\n",
        "        title=\"Resume to YAML Formatter\",\n",
        "        description=\"Upload a PDF resume and enter your OpenAI API key to get it formatted to a YAML template.\",\n",
        "    )\n",
        "\n",
        "    iface.launch(debug=True, share=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "jO95324qphrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Huggingface space deployment Upload resume and job description and see how match your score with the job description"
      ],
      "metadata": {
        "id": "aoOxIzbYQ1MW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import io\n",
        "import os\n",
        "import PyPDF2\n",
        "from gradio.components import File, Textbox\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain import PromptTemplate\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def extract_text_from_pdf_binary(pdf_binary):\n",
        "    \"\"\"Extracts text from a PDF file binary.\"\"\"\n",
        "    text = \"\"\n",
        "    pdf_data = io.BytesIO(pdf_binary)\n",
        "    reader = PyPDF2.PdfReader(pdf_data)\n",
        "    for page in reader.pages:\n",
        "        page_text = page.extract_text()\n",
        "        if page_text:\n",
        "            text += page_text\n",
        "    return text\n",
        "\n",
        "def calculate_resume_score(resume_text, job_description):\n",
        "    \"\"\"\n",
        "    Calculates the relevance score of the resume to the job description using cosine similarity.\n",
        "\n",
        "    Parameters:\n",
        "    - resume_text (str): Text of the resume.\n",
        "    - job_description (str): Text of the job description.\n",
        "\n",
        "    Returns:\n",
        "    - score (float): Similarity score between the resume and job description.\n",
        "    \"\"\"\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform([resume_text, job_description])\n",
        "    score = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]\n",
        "    return score\n",
        "\n",
        "def format_resume_to_yaml(api_key, file_content, job_description):\n",
        "    \"\"\"Formats the content of a resume PDF file to YAML and calculates its relevance to a job description.\"\"\"\n",
        "    if not file_content:\n",
        "        raise ValueError(\"The uploaded file is empty.\")\n",
        "\n",
        "    os.environ['OPENAI_API_KEY'] = api_key\n",
        "    resume_text = extract_text_from_pdf_binary(file_content)\n",
        "\n",
        "    # Additional step to calculate the resume score relative to the job description.\n",
        "    resume_score = calculate_resume_score(resume_text, job_description)\n",
        "\n",
        "    # Formatting the resume to YAML (the existing implementation continues here)...\n",
        "    # Assume llm_chain.predict and other logic here as before.\n",
        "\n",
        "    # For demonstration, return both formatted resume (in real use, integrate this properly) and score.\n",
        "    return \"Formatted Resume in YAML (placeholder)\", resume_score\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to launch the Gradio interface with job description input.\"\"\"\n",
        "    iface = gr.Interface(\n",
        "        fn=format_resume_to_yaml,\n",
        "        inputs=[\n",
        "            Textbox(label=\"Enter your OpenAI API Key\"),\n",
        "            File(label=\"Upload your PDF resume\", type=\"binary\"),\n",
        "            Textbox(label=\"Paste the Job Description here\", lines=10)\n",
        "        ],\n",
        "        outputs=[\n",
        "            Textbox(label=\"Formatted Resume in YAML\"),\n",
        "            Textbox(label=\"Resume Score\")\n",
        "        ],\n",
        "        title=\"Resume to YAML Formatter with ATS Scoring\",\n",
        "        description=\"Upload a PDF resume, paste the job description, and enter your OpenAI API key to get the resume formatted to a YAML template and score its relevance to the job.\"\n",
        "    )\n",
        "    iface.launch(debug=True, share=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "HWD2E6BxRGDV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}